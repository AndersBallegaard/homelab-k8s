{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Homelab This is a very much work in progress repository for migrating all (or atleast most) of my homelab to k8s This repo is intentionally public to act as inspiration to others, and force me to think more about security Project structure For setup and cluster management see admin/readme.md For services running on the cluster see the cluster dir This page is autogenerated, do not edit it directly see this for more information","title":"Home"},{"location":"#homelab","text":"This is a very much work in progress repository for migrating all (or atleast most) of my homelab to k8s This repo is intentionally public to act as inspiration to others, and force me to think more about security","title":"Homelab"},{"location":"#project-structure","text":"For setup and cluster management see admin/readme.md For services running on the cluster see the cluster dir This page is autogenerated, do not edit it directly see this for more information","title":"Project structure"},{"location":"apps/apps/","text":"APPS This section describes the apps running on the cluster This page is autogenerated, do not edit it directly see this for more information","title":"Apps"},{"location":"apps/apps/#apps","text":"This section describes the apps running on the cluster This page is autogenerated, do not edit it directly see this for more information","title":"APPS"},{"location":"info/docs/","text":"About this documentation Parts of the documentation in this use templates, if markdown file is generated from a template a notice should be present at the bottom of the file. This automatic generation is used to prevent documentation getting out of sync when the same information is needed in multiple places, an example could be that the repo's readme.md file should be identical to the \"Home\" page in the documentation, this is achived by using a template for the readme.md importing the \"Home\" document How to add to this documentation Create new section First create a directory for the section, and a jinja template file # Make directory and empty jinja file mkdir -p docs/example touch docs/example/example.jinja # All files should include footer containing warning not to edit md files directly echo '{{ '{% include \\\"docs/footer.section\\\" %}' }}' >> docs/example/example.jinja This page should be added to the nav section of mkdocs.yaml, see the file or mkdocs documentation for how to do this Add page Create a new file inside the directory you want to add to. The file should follow the 'relevant_name.section' naming scheme. Treat this file as a markdown file, and add the content you want Once you are ready to include it in the documentation add a line to the directorys .jinja file, the line should look something like below {{ '{% include \\\"example/world_domination.section\\\" %}' }} Note, this should always be placed above the footer inclusion While there aren't many restrictions on the content in a section, it is expected that each section starts with an H1 header Documentation deployment Deployment to github pages is not automatic, in order to deploy, follow this process # The following commands are all from the root of the project # Build documentation ./build_docs.sh # Source venv source .venv/bin/activate # Run locally to validate changes before deploying mkdocs serve # Use mkdocs github pages feature to deploy mkdocs gh-deploy","title":"Documentation"},{"location":"info/docs/#about-this-documentation","text":"Parts of the documentation in this use templates, if markdown file is generated from a template a notice should be present at the bottom of the file. This automatic generation is used to prevent documentation getting out of sync when the same information is needed in multiple places, an example could be that the repo's readme.md file should be identical to the \"Home\" page in the documentation, this is achived by using a template for the readme.md importing the \"Home\" document","title":"About this documentation"},{"location":"info/docs/#how-to-add-to-this-documentation","text":"","title":"How to add to this documentation"},{"location":"info/docs/#create-new-section","text":"First create a directory for the section, and a jinja template file # Make directory and empty jinja file mkdir -p docs/example touch docs/example/example.jinja # All files should include footer containing warning not to edit md files directly echo '{{ '{% include \\\"docs/footer.section\\\" %}' }}' >> docs/example/example.jinja This page should be added to the nav section of mkdocs.yaml, see the file or mkdocs documentation for how to do this","title":"Create new section"},{"location":"info/docs/#add-page","text":"Create a new file inside the directory you want to add to. The file should follow the 'relevant_name.section' naming scheme. Treat this file as a markdown file, and add the content you want Once you are ready to include it in the documentation add a line to the directorys .jinja file, the line should look something like below {{ '{% include \\\"example/world_domination.section\\\" %}' }} Note, this should always be placed above the footer inclusion While there aren't many restrictions on the content in a section, it is expected that each section starts with an H1 header","title":"Add page"},{"location":"info/docs/#documentation-deployment","text":"Deployment to github pages is not automatic, in order to deploy, follow this process # The following commands are all from the root of the project # Build documentation ./build_docs.sh # Source venv source .venv/bin/activate # Run locally to validate changes before deploying mkdocs serve # Use mkdocs github pages feature to deploy mkdocs gh-deploy","title":"Documentation deployment"},{"location":"infra/conformance_testing/","text":"Conformance testing Test cluster conformance In order to run tests, from a terminal running in this directory run the following command Note: If conformane testing have previously been run on this k8s version, the test results will be overwriten ./run_test.sh","title":"Conformance testing"},{"location":"infra/conformance_testing/#conformance-testing","text":"","title":"Conformance testing"},{"location":"infra/conformance_testing/#test-cluster-conformance","text":"In order to run tests, from a terminal running in this directory run the following command Note: If conformane testing have previously been run on this k8s version, the test results will be overwriten ./run_test.sh","title":"Test cluster conformance"},{"location":"infra/fluxcd/","text":"","title":"FluxCD"},{"location":"infra/kubernetes/","text":"","title":"K8S"},{"location":"infra/traefik/","text":"","title":"Traefik"},{"location":"infra/deployment/prepare_admin_node/","text":"Prepare admin node To convert an ubuntu machine to an admin node run this command. This script uses git over SSH, so make sure the admin node have ssh keys created, and those keys have been added to github The script does the following - Installs openTofu - Installs git - Downloads this repository - Installs talosctl - Installs kubectl - Installs helm - Installs flux curl --proto '=https' --tlsv1.2 -fsSL https://raw.githubusercontent.com/AndersBallegaard/homelab-k8s/refs/heads/main/admin/prepare_admin_node.sh | bash","title":"Prepare admin node"},{"location":"infra/deployment/prepare_admin_node/#prepare-admin-node","text":"To convert an ubuntu machine to an admin node run this command. This script uses git over SSH, so make sure the admin node have ssh keys created, and those keys have been added to github The script does the following - Installs openTofu - Installs git - Downloads this repository - Installs talosctl - Installs kubectl - Installs helm - Installs flux curl --proto '=https' --tlsv1.2 -fsSL https://raw.githubusercontent.com/AndersBallegaard/homelab-k8s/refs/heads/main/admin/prepare_admin_node.sh | bash","title":"Prepare admin node"},{"location":"infra/deployment/prepare_proxmox/","text":"Prepare proxmox for cloudinit In case proxmox isn't ready for cloudinit of talos, this is how to set it up. Currently this is done from the proxmox UI as a one of thing # Download a talos image from the talos image factory, it needs to be a nocloud image # The image should be placed under the name \"talos-nocloud-amd64.iso\" in the shared vm datastore # Create a VM with the 1g disk on shared storage, and attach the iso. Ram and CPU doesn't matter # Don't start the VM # The vm MUST be named talos-template, and should have the ID 9100 # CPU Type should be host for best performace # Disk size is intentionally below recormendations for faster template deployments, cloud init will resize to whatever the VM is speced for # # Convert VM to template","title":"Prepare proxmox"},{"location":"infra/deployment/prepare_proxmox/#prepare-proxmox-for-cloudinit","text":"In case proxmox isn't ready for cloudinit of talos, this is how to set it up. Currently this is done from the proxmox UI as a one of thing # Download a talos image from the talos image factory, it needs to be a nocloud image # The image should be placed under the name \"talos-nocloud-amd64.iso\" in the shared vm datastore # Create a VM with the 1g disk on shared storage, and attach the iso. Ram and CPU doesn't matter # Don't start the VM # The vm MUST be named talos-template, and should have the ID 9100 # CPU Type should be host for best performace # Disk size is intentionally below recormendations for faster template deployments, cloud init will resize to whatever the VM is speced for # # Convert VM to template","title":"Prepare proxmox for cloudinit"},{"location":"infra/deployment/setup_cluster/","text":"Provision Cluster # Set env variables export TF_VAR_cloudflare_api_token=READ_WRITE_TOKEN export TF_VAR_cloudflare_zone_id=DOMAIN_ZONEID export TF_VAR_vm_user_username=anders export TF_VAR_vm_user_sshkey=\"SSH PUBLIC ID for authentication\" export TF_VAR_proxmox_username=USERNAME@pam export TF_VAR_proxmox_password=PROXMOX_PASSWORD export TF_VAR_proxmox_api_url=https://PROXMOX_SERVER:8006/api2/json # Initialize openTofu cd admin tofu init # Bootstrap the cluster ./patch_infra.sh Setup Cillium CNI helm repo add cilium https://helm.cilium.io/ helm install cilium cilium/cilium --namespace kube-system -f cilium-values.yaml Setup rook helm repo add rook-release https://charts.rook.io/release helm install --create-namespace --namespace rook-ceph rook-ceph rook-release/rook-ceph kubectl label namespace rook-ceph pod-security.kubernetes.io/enforce=privileged helm install --create-namespace --namespace rook-ceph rook-ceph-cluster --set operatorNamespace=rook-ceph rook-release/rook-ceph-cluster # NOTE: FluxCD will also deploy some Rook config, setting up rook/ceph will take forever, give it atleast 30 minutes before panicing Setup fluxCD flux bootstrap github \\ --token-auth \\ --owner=andersballegaard \\ --repository=homelab-k8s \\ --branch=main \\ --path=cluster \\ --personal","title":"Setup cluster"},{"location":"infra/deployment/setup_cluster/#provision-cluster","text":"# Set env variables export TF_VAR_cloudflare_api_token=READ_WRITE_TOKEN export TF_VAR_cloudflare_zone_id=DOMAIN_ZONEID export TF_VAR_vm_user_username=anders export TF_VAR_vm_user_sshkey=\"SSH PUBLIC ID for authentication\" export TF_VAR_proxmox_username=USERNAME@pam export TF_VAR_proxmox_password=PROXMOX_PASSWORD export TF_VAR_proxmox_api_url=https://PROXMOX_SERVER:8006/api2/json # Initialize openTofu cd admin tofu init # Bootstrap the cluster ./patch_infra.sh","title":"Provision Cluster"},{"location":"infra/deployment/setup_cluster/#setup-cillium-cni","text":"helm repo add cilium https://helm.cilium.io/ helm install cilium cilium/cilium --namespace kube-system -f cilium-values.yaml","title":"Setup Cillium CNI"},{"location":"infra/deployment/setup_cluster/#setup-rook","text":"helm repo add rook-release https://charts.rook.io/release helm install --create-namespace --namespace rook-ceph rook-ceph rook-release/rook-ceph kubectl label namespace rook-ceph pod-security.kubernetes.io/enforce=privileged helm install --create-namespace --namespace rook-ceph rook-ceph-cluster --set operatorNamespace=rook-ceph rook-release/rook-ceph-cluster # NOTE: FluxCD will also deploy some Rook config, setting up rook/ceph will take forever, give it atleast 30 minutes before panicing","title":"Setup rook"},{"location":"infra/deployment/setup_cluster/#setup-fluxcd","text":"flux bootstrap github \\ --token-auth \\ --owner=andersballegaard \\ --repository=homelab-k8s \\ --branch=main \\ --path=cluster \\ --personal","title":"Setup fluxCD"},{"location":"troubleshooting/port-forwarding/","text":"Port forwarding For troubleshooting purposes it is often practical to port forward a service in k8s. This is also the only way to access certine admin interfaces that aren't exposed with an ingress Generic service This is the general way to expose any service with a port-forward. In a step to reduce the use of legacy IP, binding to ipv6 is forced in this example, note you might want to bind to ::1 instead of :: kubectl -n NAMESPACE port-forward svc/SERVICE_NAME PORT:PORT --address=\"::\" Capacitor If troubleshooting fluxcd, it might be nice to have a more visual representation of what services are in fluxcd. For this purpose a capacitor deployment exists, but isn't exposed via any ingress for security reasons, to forward it run the following command kubectl -n flux-system port-forward svc/capacitor 9000:9000 --address=\"::1\" CEPH dashboard When troubleshooting ceph/rook, it might be nice to use the ceph dashboard, it can be exposed using the following command kubectl -n rook-ceph port-forward svc/rook-ceph-mgr-dashboard 7000:7000 --address=\"::\" In order to login use the username \"admin\", and the password provided by the following command. kubectl get secret -n rook-ceph -o jsonpath='{.data.password}' rook-ceph-dashboard-password | base64 -d","title":"K8S Port forwarding"},{"location":"troubleshooting/port-forwarding/#port-forwarding","text":"For troubleshooting purposes it is often practical to port forward a service in k8s. This is also the only way to access certine admin interfaces that aren't exposed with an ingress","title":"Port forwarding"},{"location":"troubleshooting/port-forwarding/#generic-service","text":"This is the general way to expose any service with a port-forward. In a step to reduce the use of legacy IP, binding to ipv6 is forced in this example, note you might want to bind to ::1 instead of :: kubectl -n NAMESPACE port-forward svc/SERVICE_NAME PORT:PORT --address=\"::\"","title":"Generic service"},{"location":"troubleshooting/port-forwarding/#capacitor","text":"If troubleshooting fluxcd, it might be nice to have a more visual representation of what services are in fluxcd. For this purpose a capacitor deployment exists, but isn't exposed via any ingress for security reasons, to forward it run the following command kubectl -n flux-system port-forward svc/capacitor 9000:9000 --address=\"::1\"","title":"Capacitor"},{"location":"troubleshooting/port-forwarding/#ceph-dashboard","text":"When troubleshooting ceph/rook, it might be nice to use the ceph dashboard, it can be exposed using the following command kubectl -n rook-ceph port-forward svc/rook-ceph-mgr-dashboard 7000:7000 --address=\"::\" In order to login use the username \"admin\", and the password provided by the following command. kubectl get secret -n rook-ceph -o jsonpath='{.data.password}' rook-ceph-dashboard-password | base64 -d","title":"CEPH dashboard"}]}